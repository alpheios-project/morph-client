{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap","webpack:///./base_adapter.js","webpack:///./driver.js","webpack:///./tufts/adapter.js","webpack:///./tufts/engine/aramorph.js","webpack:///./tufts/engine/data/test-data.js","webpack:///./tufts/engine/hazm.js","webpack:///./tufts/engine/morpheusgrc.js","webpack:///./tufts/engine/whitakers.js","webpack:///./tufts/lib.js","webpack:///external \"alpheios-data-models\""],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kDAA0C,gCAAgC;AAC1E;AACA;;AAEA;AACA;AACA;AACA,gEAAwD,kBAAkB;AAC1E;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAyC,iCAAiC;AAC1E,wHAAgH,mBAAmB,EAAE;AACrI;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;;;;;;;AClFA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,qEAAqE,KAAK;AAC1E;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;AC3FA;AACA;AACQ;;;;;;;;;;;;;;;;;;;;;;;;ACFR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa,OAAO;AACpB;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,KAAK;AACL,oCAAoC;AACpC;AACA;AACA,sRAAsF,yBAAyB;AAC/G;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7QA;AACA;;AAEA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC;AACA;AACA;;;;;;;;;;;;;;;;;ACtBA;AACA;;AAEA;;AAEA;AACA,wCAAwC,oCAAoC;;AAE5E;;;;;;;;;;;;;;;;;ACRA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;;;;;;;;;;;;;;;;ACnBA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED;;;;;;;;;;;;;;AC3CA;AAAA;AAAA;AACA;AACA;AAC0C;;AAE1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wBAAwB;AACvC,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,OAAO;AACtB,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0CAA0C,cAAc,gBAAgB,YAAY,QAAQ,mBAAmB,cAAc,mBAAmB;AAChJ;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe,SAAS;AACxB;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT,0CAA0C,mBAAmB,gBAAgB,YAAY,QAAQ,mBAAmB,cAAc,mBAAmB;AACrJ;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,qEAAqE,EAAE;AAChH;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AChLA,kE","file":"alpheios-morph-client.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"alpheios-data-models\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"alpheios-data-models\"], factory);\n\telse {\n\t\tvar a = typeof exports === 'object' ? factory(require(\"alpheios-data-models\")) : factory(root[\"alpheios-data-models\"]);\n\t\tfor(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];\n\t}\n})(window, function(__WEBPACK_EXTERNAL_MODULE_alpheios_data_models__) {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = \"./driver.js\");\n","/**\n * Base Adapter Class for a Morphology Service Client\n */\nclass BaseAdapter {\n  /**\n   * Method which is used to prepare a lookup request according\n   * to the adapter specific logic\n   * @param {string} lang - the language code\n   * @param {string} word - the word to lookup\n   * @returns {string} the url for the request\n   */\n  prepareRequestUrl (lang, word) {\n    /** must be overridden in the adapter implementation class **/\n    return null\n  }\n\n  /**\n   * Lookup the supplied word using the preconfigured engines and\n   * and return a Homonym\n   * @param {string} lang - ISO 639-2 language code for the word\n   * @param {string} word - the word to lookup\n   * @return {Homonym} homonym object\n   */\n  async getHomonym (lang, word) {\n    // implement in the derived adapater class\n    return undefined\n  }\n\n  /**\n   * Fetch response from a remote URL\n   * @param {string} lang - the language code\n   * @param {string} word - the word to lookup\n   * @returns {Promise} a promse which if successful resolves to json response object\n   *                    with the results of the analysis\n   */\n  fetch (lang, word) {\n    let url = this.prepareRequestUrl(lang, word)\n    return new Promise((resolve, reject) => {\n      if (url) {\n        window.fetch(url).then(\n          function (response) {\n            try {\n              if (response.ok) {\n                let json = response.json()\n                resolve(json)\n              } else {\n                reject(response.statusText)\n              }\n            } catch (error) {\n              reject(error)\n            }\n          }\n        ).catch((error) => {\n          reject(error)\n        }\n        )\n      } else {\n        reject(new Error(`Unable to prepare parser request url for ${lang}`))\n      }\n    })\n  }\n\n  /**\n   * Fetch test data to test the adapter\n   * @param {string} lang - the language code\n   * @param {string} word - the word to lookup\n   * @returns {Promise} a promse which if successful resolves to json response object\n   *                    with the test data\n   */\n  fetchTestData (lang, word) {\n    return new Promise((resolve, reject) => {\n      try {\n        let data = {}\n        resolve(data)\n      } catch (error) {\n        reject(error)\n      }\n    })\n  }\n\n  /**\n   * A function that maps a morphological service's specific data types and values into an inflection library standard.\n   * @param {object} jsonObj - A JSON data from the fetch request\n   * @param {object} targetWord - the original target word of the analysis\n   * @returns {Homonym} A library standard Homonym object.\n   */\n  transform (jsonObj, targetWord) {\n    return {}\n  }\n}\n\nexport default BaseAdapter\n","import AlpheiosTuftsAdapter from './tufts/adapter'\nimport BaseAdapter from './base_adapter'\nexport { BaseAdapter, AlpheiosTuftsAdapter }\n","import BaseAdapter from '../base_adapter'\nimport Whitakers from './engine/whitakers'\nimport Morpheusgrc from './engine/morpheusgrc'\nimport Aramorph from './engine/aramorph'\nimport Hazm from './engine/hazm'\nimport * as Models from 'alpheios-data-models'\nimport WordTestData from './engine/data/test-data'\nimport DefaultConfig from './config.json'\n\nclass AlpheiosTuftsAdapter extends BaseAdapter {\n  /**\n   * A Morph Client Adapter for the Tufts Morphology Service\n   * @constructor\n   * @param {object} config configuraiton object\n   */\n  constructor (config = {}) {\n    super()\n    try {\n      this.config = JSON.parse(DefaultConfig)\n    } catch (e) {\n      this.config = Object.assign({}, DefaultConfig)\n    }\n    Object.assign(this.config, config)\n    this.engineMap = new Map(([ Whitakers, Morpheusgrc, Aramorph, Hazm ]).map((e) => { return [ e.engine, e ] }))\n  }\n\n  getEngineLanguageMap (lang) {\n    if (this.config.engine[lang]) {\n      return this.engineMap.get(this.config.engine[lang][0])\n    } else {\n      return null\n    }\n  }\n\n  prepareRequestUrl (lang, word) {\n    let engine = this.getEngineLanguageMap(lang)\n    if (engine) {\n      let code = engine.engine\n      return this.config.url.replace('r_WORD', word).replace('r_ENGINE', code).replace('r_LANG', lang)\n    } else {\n      return null\n    }\n  }\n\n  fetchTestData (lang, word) {\n    return new Promise((resolve, reject) => {\n      try {\n        let wordData = new WordTestData().get(word)\n        let json = JSON.parse(wordData)\n        resolve(json)\n      } catch (error) {\n        // Word is not found in test data\n        reject(error)\n      }\n    })\n  }\n\n  /**\n   * A function that maps a morphological service's specific data types and values into an inflection library standard.\n   * @param {object} jsonObj - A JSON data from a Morphological Analyzer.\n   * @param {object} targetWord - the target of the analysis\n   * @returns {Models.Homonym} A library standard Homonym object.\n   */\n  transform (jsonObj, targetWord) {\n    'use strict'\n    let lexemes = []\n    let annotationBody = jsonObj.RDF.Annotation.Body\n    if (!Array.isArray(annotationBody)) {\n      /*\n      If only one lexeme is returned, Annotation Body will not be an array but rather a single object.\n      Let's convert it to an array so we can work with it in the same way no matter what format it is.\n      */\n      if (annotationBody) {\n        annotationBody = [annotationBody]\n      } else {\n        annotationBody = []\n      }\n    }\n    let providerUri = jsonObj.RDF.Annotation.creator.Agent.about\n    let providerRights = ''\n    if (jsonObj.RDF.Annotation.rights) {\n      providerRights = jsonObj.RDF.Annotation.rights.$\n    }\n    let provider = new Models.ResourceProvider(providerUri, providerRights)\n    for (let lexeme of annotationBody) {\n      let inflectionsJSON = lexeme.rest.entry.infl\n      if (!inflectionsJSON) {\n        inflectionsJSON = []\n      } else if (!Array.isArray(inflectionsJSON)) {\n        // If only one inflection returned, it is a single object, not an array of objects.\n        // Convert it to an array for uniformity.\n        inflectionsJSON = [inflectionsJSON]\n      }\n      let lemmaElements\n      let features = [\n        ['pofs', 'part'],\n        ['case', 'grmCase'],\n        ['gend', 'gender'],\n        ['decl', 'declension'],\n        ['conj', 'conjugation'],\n        ['area', 'area'],\n        ['age', 'age'],\n        ['geo', 'geo'],\n        ['freq', 'frequency'],\n        ['note', 'note'],\n        ['pron', 'pronunciation'],\n        ['kind', 'kind']\n      ]\n      if (lexeme.rest.entry.dict) {\n        if (Array.isArray(lexeme.rest.entry.dict)) {\n          lemmaElements = lexeme.rest.entry.dict\n        } else {\n          if (!lexeme.rest.entry.dict.hdwd && inflectionsJSON[0].term) {\n            lexeme.rest.entry.dict.hdwd = {}\n            lexeme.rest.entry.dict.hdwd.lang = inflectionsJSON[0].term.lang\n            lexeme.rest.entry.dict.hdwd.$ = inflectionsJSON[0].term.stem.$ + inflectionsJSON[0].term.suff.$\n          }\n          lemmaElements = [lexeme.rest.entry.dict]\n        }\n      } else if (inflectionsJSON.length > 0 && inflectionsJSON[0].term) {\n        lemmaElements = [ inflectionsJSON[0].term ]\n      }\n      // in rare cases (e.g. conditum in Whitakers) multiple dict entries\n      // exist - always use the lemma and language from the first\n      let language = lemmaElements[0].hdwd ? lemmaElements[0].hdwd.lang : lemmaElements[0].lang\n      // Get importer based on the language\n      let mappingData = this.getEngineLanguageMap(language)\n      let lemmas = []\n      let lexemeSet = []\n      for (let entry of lemmaElements.entries()) {\n        let shortdefs = []\n        let index = entry[0]\n        let elem = entry[1]\n        let lemmaText\n        if (elem.hdwd) {\n          lemmaText = elem.hdwd.$\n        }\n        if (!lemmaText || !language) {\n          continue\n        }\n        let lemma = mappingData.parseLemma(lemmaText, language)\n        lemmas.push(lemma)\n        for (let feature of features) {\n          mappingData.mapFeature(lemma, elem, ...feature, this.config.allowUnknownValues)\n        }\n        let meanings = lexeme.rest.entry.mean\n        if (!Array.isArray(meanings)) {\n          meanings = [meanings]\n        }\n        meanings = meanings.filter((m) => m)\n        // if we have multiple dictionary elements, take the meaning with the matching index\n        if (lemmaElements.length > 1) {\n          if (meanings && meanings[index]) {\n            let meaning = meanings[index]\n            // TODO: convert a source-specific language code to ISO 639-3 if don't match\n            let lang = meaning.lang ? meaning.lang : 'eng'\n            shortdefs.push(Models.ResourceProvider.getProxy(provider,\n              new Models.Definition(meaning.$, lang, 'text/plain', lemmas[index].word)))\n          }\n        } else {\n          // Changed to prevent some weird \"Array Iterator.prototype.next called on incompatible receiver [object Unknown]\" error\n          let sDefs = meanings.map(meaning => {\n            let lang = meaning.lang ? meaning.lang : 'eng'\n            return Models.ResourceProvider.getProxy(provider,\n              new Models.Definition(meaning.$, lang, 'text/plain', lemma.word))\n          })\n          shortdefs.push(...sDefs)\n        }\n        let lexmodel = new Models.Lexeme(lemma, [])\n\n        lexmodel.meaning.appendShortDefs(shortdefs)\n        lexemeSet.push(Models.ResourceProvider.getProxy(provider, lexmodel))\n      }\n      if (lemmas.length === 0) {\n        continue\n      }\n      let inflections = []\n      for (let inflectionJSON of inflectionsJSON) {\n        let stem = inflectionJSON.term.stem ? inflectionJSON.term.stem.$ : null\n        let suffix = inflectionJSON.term.suff ? inflectionJSON.term.suff.$ : null\n        let prefix = inflectionJSON.term.pref ? inflectionJSON.term.pref.$ : null\n        let xmpl = inflectionJSON.xmlle ? inflectionJSON.xmpl.$ : null\n        let inflection = new Models.Inflection(stem, mappingData.model.languageID, suffix, prefix, xmpl)\n        if (targetWord) {\n          inflection.addFeature(new Models.Feature(Models.Feature.types.fullForm, targetWord, mappingData.model.languageID))\n        }\n        // Parse whatever grammatical features we're interested in\n        mappingData.mapFeature(inflection, inflectionJSON, 'pofs', 'part', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'case', 'grmCase', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'decl', 'declension', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'num', 'number', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'gend', 'gender', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'conj', 'conjugation', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'tense', 'tense', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'voice', 'voice', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'mood', 'mood', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'pers', 'person', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'comp', 'comparison', this.config.allowUnknownValues)\n        if (inflectionJSON.stemtype) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'stemtype', 'stemtype', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.derivtype) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'derivtype', 'derivtype', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.dial) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'dial', 'dialect', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.morph) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'morph', 'morph', this.config.allowUnknownValues)\n        }\n        // we only use the inflection if it tells us something the dictionary details do not\n        if (inflection[Models.Feature.types.grmCase] ||\n          inflection[Models.Feature.types.tense] ||\n          inflection[Models.Feature.types.mood] ||\n          inflection[Models.Feature.types.voice] ||\n          inflection[Models.Feature.types.person] ||\n          inflection[Models.Feature.types.comparison] ||\n          inflection[Models.Feature.types.stemtype] ||\n          inflection[Models.Feature.types.derivtype] ||\n          inflection[Models.Feature.types.dialect] ||\n          inflection[Models.Feature.types.morph] ||\n          inflection[Models.Feature.types.example]) {\n          inflections.push(inflection)\n        }\n        // inflection can provide lemma decl, pofs, conj\n        for (let lemma of lemmas) {\n          if (!lemma.features[Models.Feature.types.part]) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'pofs', 'part', this.config.allowUnknownValues)\n          }\n          // only take declension from inflection if lemma has no part of speech or its the same as the inflection\n          if (!lemma.features[Models.Feature.types.declension] &&\n            (!lemma.features[Models.Feature.types.part] || lemma.features[Models.Feature.types.part].isEqual(inflection[Models.Feature.types.part]))) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'decl', 'declension', this.config.allowUnknownValues)\n          }\n          // only take conjugation from inflection if lemma has a part of speech and its the same as the inflection\n          if (!lemma.features[Models.Feature.types.conjugation] &&\n            (!lemma.features[Models.Feature.types.part] || lemma.features[Models.Feature.types.part].isEqual(inflection[Models.Feature.types.part]))) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'conj', 'conjugation', this.config.allowUnknownValues)\n          }\n        }\n      }\n      for (let lex of lexemeSet) {\n        // only process if we have a lemma that differs from the target\n        // word or if we have at least a part of speech\n        if (mappingData.reportLexeme(lex)) {\n          lex.inflections = inflections\n          lexemes.push(lex)\n        }\n      }\n    }\n    if (lexemes.length > 0) {\n      return new Models.Homonym(lexemes, targetWord)\n    } else {\n      return undefined\n    }\n  }\n\n  async getHomonym (lang, word) {\n    let jsonObj = await this.fetch(lang, word)\n    if (jsonObj) {\n      let homonym = this.transform(jsonObj, word)\n      return homonym\n    } else {\n      // No data found for this word\n      return undefined\n    }\n  }\n}\n\nexport default AlpheiosTuftsAdapter\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.ArabicLanguageModel, 'aramorph')\n\nexport default data\n","import Cupidinibus from './latin_noun_cupidinibus.json'\nimport Mare from './latin_noun_adj_mare.json'\nimport Cepit from './latin_verb_cepit.json'\nimport Pilsopo from './greek_noun_pilsopo.json'\n\nclass WordTestData {\n  constructor () {\n    this._words = {\n      'cupidinibus': Cupidinibus,\n      'mare': Mare,\n      'cepit': Cepit,\n      'φιλόσοφος': Pilsopo\n    }\n  }\n\n  get (word) {\n    if (this._words.hasOwnProperty(word)) {\n      return this._words[word]\n    }\n    throw new Error(`Word \"${word}\" does not exist in test data`)\n  }\n}\nexport default WordTestData\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.PersianLanguageModel, 'hazm')\n\n// hazm allow all lemmas in without respect features as all we use it for is lemmatizing\ndata.setLexemeFilter(function (lexeme) { return Boolean(lexeme.lemma.word) })\n\nexport default data\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.GreekLanguageModel, 'morpheusgrc')\n\n/*\nBelow are value conversion maps for each grammatical feature to be parsed.\nFormat:\ndata.addFeature(typeName).add(providerValueName, LibValueName);\n(functions are chainable)\nTypes and values that are unknown (undefined) will be skipped during parsing.\n */\n\ndata.addFeature(Models.Feature.types.gender).importer\n  .map('masculine feminine', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2]])\n\ndata.addFeature(Models.Feature.types.declension).importer\n  .map('1st & 2nd', [[Models.Constants.ORD_1ST, 1], [Models.Constants.ORD_2ND, 2]])\n\nexport default data\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.LatinLanguageModel, 'whitakerLat')\n\n/*\nBelow are value conversion maps for each grammatical feature to be parsed.\nFormat:\ndata.addFeature(typeName).add(providerValueName, LibValueName);\n(functions are chainable)\nTypes and values that are unknown (undefined) will be skipped during parsing.\n */\n\n// TODO  - per inflections.xsd\n// Whitakers Words uses packon and tackon in POFS, not sure how\n\ndata.addFeature(Models.Feature.types.gender).importer\n  .map('common', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2]])\n  .map('all', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2], [Models.Constants.GEND_NEUTER, 3]])\n\ndata.addFeature(Models.Feature.types.tense).importer\n  .map('future_perfect', Models.Constants.TENSE_FUTURE_PERFECT)\n\ndata.setLemmaParser(function (lemma) {\n  // Whitaker's Words returns principal parts for some words\n  // and sometimes has a space separted stem and suffix\n  let parsed, primary\n  let parts = []\n  let lemmas = lemma.split(', ')\n  for (let [index, l] of lemmas.entries()) {\n    let normalized = l.split(' ')[0]\n    if (index === 0) {\n      primary = normalized\n    }\n    parts.push(normalized)\n  }\n  if (primary) {\n    parsed = new Models.Lemma(primary, this.model.languageCode, parts)\n  }\n\n  return parsed\n})\n\nexport default data\n","/*\nObjects of a morphology analyzer's library\n */\nimport { Feature, Lemma, FeatureImporter } from 'alpheios-data-models'\n\n/**\n * Holds all information required to transform from morphological analyzer's grammatical feature values to the\n * library standards. There is one ImportData object per language.\n */\nclass ImportData {\n  /**\n     * Creates an ImportData object for the language provided.\n     * @param {Function<LanguageModel>} model - A language model of the import data.\n     * @param {string} engine - engine code\n     */\n  constructor (model, engine) {\n    'use strict'\n    this.model = model\n    this.engine = engine\n    // add all the features that the language supports so that we\n    // can return the default values if we don't need to import a mapping\n    for (let featureName of Object.keys(this.model.features)) {\n      this.addFeature(featureName)\n    }\n    // may be overridden by specific engine use via setLemmaParser\n    this.parseLemma = function (lemma) { return new Lemma(lemma, this.model.languageID) }\n    // may be overridden by specific engine use via setPropertyParser - default just returns the property value\n    // as a list\n    this.parseProperty = function (propertyName, propertyValue) {\n      let propertyValues = []\n      if (propertyName === 'decl') {\n        propertyValues = propertyValue.split('&').map((p) => p.trim())\n      } else if (propertyName === 'comp' && propertyValue === 'positive') {\n        propertyValues = []\n      } else {\n        propertyValues = [propertyValue]\n      }\n      return propertyValues\n    }\n    // may be overridden by specifc engine use via setLexemeFilter - default assumes we will have a part of speech\n    this.reportLexeme = function (lexeme) {\n      return lexeme.lemma.features[Feature.types.part]\n    }\n  }\n\n  /**\n     * Adds a grammatical feature whose values to be mapped.\n     * @param {string} featureName - A name of a grammatical feature (i.e. declension, number, etc.)\n     * @return {Object} An object that represent a newly created grammatical feature.\n     */\n  addFeature (featureName) {\n    this[featureName] = {}\n    let model = this.model\n\n    this[featureName].add = function add (providerValue, alpheiosValue) {\n      this[providerValue] = alpheiosValue\n      return this\n    }\n\n    this[featureName].get = function get (providerValue, sortOrder = 1, allowUnknownValues = false) {\n      let mappedValue = []\n      if (!this.importer.has(providerValue)) {\n        // if the providerValue matches the model value or the model value\n        // is unrestricted, return a feature with the providerValue and order\n        if (model.typeFeature(featureName).hasValue(providerValue) ||\n            model.typeFeature(featureName).valuesUnrestricted) {\n          mappedValue = model.typeFeature(featureName).createFeature(providerValue, sortOrder)\n        } else {\n          let message = `Unknown value \"${providerValue}\" of feature \"${featureName}\" for ${model.languageCode} (allowed = ${allowUnknownValues})`\n          if (allowUnknownValues) {\n            console.log(message)\n            mappedValue = model.typeFeature(featureName).createFeature(providerValue, sortOrder)\n          } else {\n            throw new Error(message)\n          }\n        }\n      } else {\n        let tempValue = this.importer.get(providerValue)\n        if (Array.isArray(tempValue)) {\n          mappedValue = model.typeFeature(featureName).createFeatures(tempValue, sortOrder)\n        } else {\n          mappedValue = model.typeFeature(featureName).createFeature(tempValue, sortOrder)\n        }\n      }\n      return mappedValue\n    }\n\n    /**\n     * @param {Object[]} data - An array of objects with `providerData` (an item value) and `sortOrder` fields\n     * @param allowUnknownValues\n     * @return {Feature}\n     */\n    this[featureName].getMultiple = function get (data, allowUnknownValues = false) {\n      let values = [] // Converts values from `data` into `values` array\n      for (const item of data) {\n        if (this.importer.has(item.providerValue)) {\n          let value = this.importer.get(item.providerValue)\n          if (Array.isArray(value)) {\n            // if the import returns an array, it should already have the sortOrder\n            values = value\n          } else {\n            values = [[value, item.sortOrder]]\n          }\n        } else if (model.typeFeature(featureName).hasValue(item.providerValue) ||\n          model.typeFeature(featureName).valuesUnrestricted) {\n          values.push([item.providerValue, item.sortOrder])\n        } else {\n          let message = `Unknown value \"${item.providerValue}\" of feature \"${featureName}\" for ${model.languageCode} (allowed = ${allowUnknownValues})`\n          if (allowUnknownValues) {\n            console.log(message)\n            values.push([item.providerValue, item.sortOrder])\n          } else {\n            throw new Error(message)\n          }\n        }\n      }\n      return model.typeFeature(featureName).createFeatures(values)\n    }\n\n    this[featureName].importer = new FeatureImporter()\n\n    return this[featureName]\n  }\n\n  /**\n   * Add an engine-specific lemma parser\n   */\n  setLemmaParser (callback) {\n    this.parseLemma = callback\n  }\n\n  /**\n   * Add an engine-specific property parser\n   */\n  setPropertyParser (callback) {\n    this.parseProperty = callback\n  }\n\n  /**\n   * Add an engine-specific lexeme filter\n   */\n  setLexemeFilter (callback) {\n    this.reportLexeme = callback\n  }\n\n  /**\n   * Maps property of a single feature type to a single Feature object with one or more values\n   * (if this feature has multiple values). Feature is stored as a property of the supplied model object.\n   * @param {object} model the model object to which the feature will be added\n   * @param {object} inputElem the input data element\n   * @param {object} inputName the  property name in the input data\n   * @param {string} featureName the name of the feature it will be mapped to\n   * @param {boolean} allowUnknownValues flag to indicate if unknown values are allowed\n   */\n  mapFeature (model, inputElem, inputName, featureName, allowUnknownValues) {\n    let values = []\n    let inputItem = inputElem[inputName]\n    if (inputItem) {\n      if (Array.isArray(inputItem)) {\n        // There are multiple values of this feature\n        for (let e of inputItem) {\n          values.push(...this.parseProperty(inputName, e.$))\n        }\n      } else {\n        values = this.parseProperty(inputName, inputItem.$)\n      }\n      // `values` is always an array as an array is a return value of `parseProperty`\n    }\n    if (values.length > 0) {\n      // There are some values found\n      values = values.map(v => { return { providerValue: v, sortOrder: inputItem.order ? inputItem.order : 1 } })\n      let feature = this[Feature.types[featureName]].getMultiple(values, allowUnknownValues)\n      model.addFeature(feature)\n    }\n  }\n}\nexport default ImportData\n","module.exports = __WEBPACK_EXTERNAL_MODULE_alpheios_data_models__;"],"sourceRoot":""}