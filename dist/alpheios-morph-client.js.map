{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap","webpack:///../node_modules/webpack/buildin/module.js","webpack:///../node_modules/xmltojson/lib/xmlToJSON.js","webpack:///./alpheiostb/adapter.js","webpack:///./base_adapter.js","webpack:///./driver.js","webpack:///./tufts/adapter.js","webpack:///./tufts/engine/aramorph.js","webpack:///./tufts/engine/data/test-data.js","webpack:///./tufts/engine/hazm.js","webpack:///./tufts/engine/morpheusgrc.js","webpack:///./tufts/engine/whitakers.js","webpack:///./tufts/lib.js","webpack:///external \"alpheios-data-models\""],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kDAA0C,gCAAgC;AAC1E;AACA;;AAEA;AACA;AACA;AACA,gEAAwD,kBAAkB;AAC1E;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAyC,iCAAiC;AAC1E,wHAAgH,mBAAmB,EAAE;AACrI;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;;;;;;;;;;;8CCrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAwB;AACxB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,yBAAyB,wCAAwC;AACjE;AACA;AACA;;AAEA;AACA;;AAEA,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA;;AAEA,4CAA4C;AAC5C;AACA,iBAAiB;AACjB;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB;;AAEA;AACA;AACA,uDAAuD,sCAAsC;AAC7F;;AAEA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;;AAEA,yBAAyB;AACzB;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB,gDAAgD;;AAEhD;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB;AACrB;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,2BAA2B;AACpC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA,CAAC,SAAS;;AAEV;AACA,+DAAyE,mBAAmB;AAAA;;;;;;;;;;;;;;;;;;;;;;ACjP5F;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa,OAAO;AACpB;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,KAAK;AACL,oCAAoC;AACpC;AACA;AACA,mBAAmB;AACnB;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,yDAAyD,KAAK;AAC9D;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iEAAiE,QAAQ,eAAe;AACxF;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9HA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,qEAAqE,sBAAsB;AAC3F;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;AC9FA;AACA;AACA;AACQ;;;;;;;;;;;;;;;;;;;;;;;;ACHR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa,OAAO;AACpB;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,KAAK;AACL,oCAAoC;AACpC;AACA;AACA,sRAAsF,yBAAyB;AAC/G;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9QA;AACA;;AAEA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC;AACA;AACA;;;;;;;;;;;;;;;;;ACtBA;AACA;;AAEA;;AAEA;AACA,wCAAwC,oCAAoC;;AAE5E;;;;;;;;;;;;;;;;;ACRA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;;;;;;;;;;;;;;;;ACnBA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED;;;;;;;;;;;;;;AC3CA;AAAA;AAAA;AACA;AACA;AAC0C;;AAE1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wBAAwB;AACvC,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,OAAO;AACtB,gBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0CAA0C,cAAc,gBAAgB,YAAY,QAAQ,mBAAmB,cAAc,mBAAmB;AAChJ;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe,SAAS;AACxB;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT,0CAA0C,mBAAmB,gBAAgB,YAAY,QAAQ,mBAAmB,cAAc,mBAAmB;AACrJ;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,qEAAqE,EAAE;AAChH;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AChLA,kE","file":"alpheios-morph-client.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"alpheios-data-models\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"alpheios-data-models\"], factory);\n\telse {\n\t\tvar a = typeof exports === 'object' ? factory(require(\"alpheios-data-models\")) : factory(root[\"alpheios-data-models\"]);\n\t\tfor(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];\n\t}\n})(window, function(__WEBPACK_EXTERNAL_MODULE_alpheios_data_models__) {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = \"./driver.js\");\n","module.exports = function(module) {\n\tif (!module.webpackPolyfill) {\n\t\tmodule.deprecate = function() {};\n\t\tmodule.paths = [];\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n","/* Copyright 2015 William Summers, MetaTribal LLC\n * adapted from https://developer.mozilla.org/en-US/docs/JXON\n *\n * Licensed under the MIT License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     https://opensource.org/licenses/MIT\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @author William Summers\n *\n */\n\nvar xmlToJSON = (function () {\n\n    this.version = \"1.3.5\";\n\n    var options = { // set up the default options\n        mergeCDATA: true, // extract cdata and merge with text\n        grokAttr: true, // convert truthy attributes to boolean, etc\n        grokText: true, // convert truthy text/attr to boolean, etc\n        normalize: true, // collapse multiple spaces to single space\n        xmlns: true, // include namespaces as attribute in output\n        namespaceKey: '_ns', // tag name for namespace objects\n        textKey: '_text', // tag name for text nodes\n        valueKey: '_value', // tag name for attribute values\n        attrKey: '_attr', // tag for attr groups\n        cdataKey: '_cdata', // tag for cdata nodes (ignored if mergeCDATA is true)\n        attrsAsObject: true, // if false, key is used as prefix to name, set prefix to '' to merge children and attrs.\n        stripAttrPrefix: true, // remove namespace prefixes from attributes\n        stripElemPrefix: true, // for elements of same name in diff namespaces, you can enable namespaces and access the nskey property\n        childrenAsArray: true // force children into arrays\n    };\n\n    var prefixMatch = new RegExp(/(?!xmlns)^.*:/);\n    var trimMatch = new RegExp(/^\\s+|\\s+$/g);\n\n    this.grokType = function (sValue) {\n        if (/^\\s*$/.test(sValue)) {\n            return null;\n        }\n        if (/^(?:true|false)$/i.test(sValue)) {\n            return sValue.toLowerCase() === \"true\";\n        }\n        if (isFinite(sValue)) {\n            return parseFloat(sValue);\n        }\n        return sValue;\n    };\n\n    this.parseString = function (xmlString, opt) {\n        return this.parseXML(this.stringToXML(xmlString), opt);\n    }\n\n    this.parseXML = function (oXMLParent, opt) {\n\n        // initialize options\n        for (var key in opt) {\n            options[key] = opt[key];\n        }\n\n        var vResult = {},\n            nLength = 0,\n            sCollectedTxt = \"\";\n\n        // parse namespace information\n        if (options.xmlns && oXMLParent.namespaceURI) {\n            vResult[options.namespaceKey] = oXMLParent.namespaceURI;\n        }\n\n        // parse attributes\n        // using attributes property instead of hasAttributes method to support older browsers\n        if (oXMLParent.attributes && oXMLParent.attributes.length > 0) {\n            var vAttribs = {};\n\n            for (nLength; nLength < oXMLParent.attributes.length; nLength++) {\n                var oAttrib = oXMLParent.attributes.item(nLength);\n                vContent = {};\n                var attribName = '';\n\n                if (options.stripAttrPrefix) {\n                    attribName = oAttrib.name.replace(prefixMatch, '');\n\n                } else {\n                    attribName = oAttrib.name;\n                }\n\n                if (options.grokAttr) {\n                    vContent[options.valueKey] = this.grokType(oAttrib.value.replace(trimMatch, ''));\n                } else {\n                    vContent[options.valueKey] = oAttrib.value.replace(trimMatch, '');\n                }\n\n                if (options.xmlns && oAttrib.namespaceURI) {\n                    vContent[options.namespaceKey] = oAttrib.namespaceURI;\n                }\n\n                if (options.attrsAsObject) { // attributes with same local name must enable prefixes\n                    vAttribs[attribName] = vContent;\n                } else {\n                    vResult[options.attrKey + attribName] = vContent;\n                }\n            }\n\n            if (options.attrsAsObject) {\n                vResult[options.attrKey] = vAttribs;\n            } else { }\n        }\n\n        // iterate over the children\n        if (oXMLParent.hasChildNodes()) {\n            for (var oNode, sProp, vContent, nItem = 0; nItem < oXMLParent.childNodes.length; nItem++) {\n                oNode = oXMLParent.childNodes.item(nItem);\n\n                if (oNode.nodeType === 4) {\n                    if (options.mergeCDATA) {\n                        sCollectedTxt += oNode.nodeValue;\n                    } else {\n                        if (vResult.hasOwnProperty(options.cdataKey)) {\n                            if (vResult[options.cdataKey].constructor !== Array) {\n                                vResult[options.cdataKey] = [vResult[options.cdataKey]];\n                            }\n                            vResult[options.cdataKey].push(oNode.nodeValue);\n\n                        } else {\n                            if (options.childrenAsArray) {\n                                vResult[options.cdataKey] = [];\n                                vResult[options.cdataKey].push(oNode.nodeValue);\n                            } else {\n                                vResult[options.cdataKey] = oNode.nodeValue;\n                            }\n                        }\n                    }\n                } /* nodeType is \"CDATASection\" (4) */\n                else if (oNode.nodeType === 3) {\n                    sCollectedTxt += oNode.nodeValue;\n                } /* nodeType is \"Text\" (3) */\n                else if (oNode.nodeType === 1) { /* nodeType is \"Element\" (1) */\n\n                    if (nLength === 0) {\n                        vResult = {};\n                    }\n\n                    // using nodeName to support browser (IE) implementation with no 'localName' property\n                    if (options.stripElemPrefix) {\n                        sProp = oNode.nodeName.replace(prefixMatch, '');\n                    } else {\n                        sProp = oNode.nodeName;\n                    }\n\n                    vContent = xmlToJSON.parseXML(oNode);\n\n                    if (vResult.hasOwnProperty(sProp)) {\n                        if (vResult[sProp].constructor !== Array) {\n                            vResult[sProp] = [vResult[sProp]];\n                        }\n                        vResult[sProp].push(vContent);\n\n                    } else {\n                        if (options.childrenAsArray) {\n                            vResult[sProp] = [];\n                            vResult[sProp].push(vContent);\n                        } else {\n                            vResult[sProp] = vContent;\n                        }\n                        nLength++;\n                    }\n                }\n            }\n        } else if (!sCollectedTxt) { // no children and no text, return null\n            if (options.childrenAsArray) {\n                vResult[options.textKey] = [];\n                vResult[options.textKey].push(null);\n            } else {\n                vResult[options.textKey] = null;\n            }\n        }\n\n        if (sCollectedTxt) {\n            if (options.grokText) {\n                var value = this.grokType(sCollectedTxt.replace(trimMatch, ''));\n                if (value !== null && value !== undefined) {\n                    vResult[options.textKey] = value;\n                }\n            } else if (options.normalize) {\n                vResult[options.textKey] = sCollectedTxt.replace(trimMatch, '').replace(/\\s+/g, \" \");\n            } else {\n                vResult[options.textKey] = sCollectedTxt.replace(trimMatch, '');\n            }\n        }\n\n        return vResult;\n    }\n\n\n    // Convert xmlDocument to a string\n    // Returns null on failure\n    this.xmlToString = function (xmlDoc) {\n        try {\n            var xmlString = xmlDoc.xml ? xmlDoc.xml : (new XMLSerializer()).serializeToString(xmlDoc);\n            return xmlString;\n        } catch (err) {\n            return null;\n        }\n    }\n\n    // Convert a string to XML Node Structure\n    // Returns null on failure\n    this.stringToXML = function (xmlString) {\n        try {\n            var xmlDoc = null;\n\n            if (window.DOMParser) {\n\n                var parser = new DOMParser();\n                xmlDoc = parser.parseFromString(xmlString, \"text/xml\");\n\n                return xmlDoc;\n            } else {\n                xmlDoc = new ActiveXObject(\"Microsoft.XMLDOM\");\n                xmlDoc.async = false;\n                xmlDoc.loadXML(xmlString);\n\n                return xmlDoc;\n            }\n        } catch (e) {\n            return null;\n        }\n    }\n\n    return this;\n}).call({});\n\nif (typeof module != \"undefined\" && module !== null && module.exports) module.exports = xmlToJSON;\nelse if (typeof define === \"function\" && define.amd) define(function () { return xmlToJSON });\n","import BaseAdapter from '../base_adapter'\nimport * as Models from 'alpheios-data-models'\nimport DefaultConfig from './config.json'\nimport xmlToJSON from 'xmltojson'\n\nclass AlpheiosTreebankAdapter extends BaseAdapter {\n  /**\n   * A Morph Client Adapter for the Tufts Morphology Service\n   * @constructor\n   * @param {object} config configuraiton object\n   */\n  constructor (config = {}) {\n    super()\n    try {\n      this.config = JSON.parse(DefaultConfig)\n    } catch (e) {\n      this.config = Object.assign({}, DefaultConfig)\n    }\n    Object.assign(this.config, config)\n    this.models = { 'lat': Models.LatinLanguageModel,\n      'grc': Models.GreekLanguageModel\n    }\n  }\n\n  /**\n   * Fetch response from a remote URL\n   * @override BaseAdapter#fetch\n   * @param {String} word is expected to be a reference to a word identifier fragement\n  *                       in a text in the form textid#wordid\n   *                      e.g. 1999.02.0066#1-1\n   */\n  fetch (lang, word) {\n    let [text, fragment] = word.split(/#/)\n    let url\n    if (this.config.texts.includes(text)) {\n      url = this.config.url.replace('r_WORD', fragment)\n    }\n    return new Promise((resolve, reject) => {\n      if (url) {\n        window.fetch(url).then(\n          function (response) {\n            try {\n              if (response.ok) {\n                let xmlString = response.text()\n                resolve(xmlString)\n              } else {\n                reject(response.statusText)\n              }\n            } catch (error) {\n              reject(error)\n            }\n          }\n        ).catch((error) => {\n          reject(error)\n        }\n        )\n      } else {\n        reject(new Error(`Invalid or unknown reference ${word}`))\n      }\n    })\n  }\n\n  /**\n   * A function that maps a morphological service's specific data types and values into an inflection library standard.\n   * @param {object} jsonObj - A JSON data from a Morphological Analyzer.\n   * @param {object} targetWord - the target of the analysis\n   * @returns {Models.Homonym} A library standard Homonym object.\n   */\n  transform (jsonObj, targetWord) {\n    'use strict'\n    let providerUri = this.config.providerUri\n    let providerRights = this.config.providerRights\n    let provider = new Models.ResourceProvider(providerUri, providerRights)\n    let hdwd = jsonObj.words[0].word[0].entry[0].dict[0].hdwd[0]\n    let lemmaText = hdwd._text\n    // the Alpheios v1 treebank data kept trailing digits on the lemmas\n    // these won't match morphology service lemmas which have them stripped\n    lemmaText = lemmaText.replace(/\\d+$/, '')\n    let model = this.models[hdwd._attr.lang._value]\n    let lemma = new Models.Lemma(lemmaText, model.languageCode)\n    let lexmodel = new Models.Lexeme(lemma, [])\n    let inflection = new Models.Inflection(lemmaText, model.languageID, null, null, null)\n    let infl = jsonObj.words[0].word[0].entry[0].infl[0]\n    inflection.addFeature(new Models.Feature(Models.Feature.types.fullForm, targetWord, model.languageID))\n    let features = [\n      ['pofs', 'part', true],\n      ['case', 'grmCase', false],\n      ['num', 'number', false],\n      ['gend', 'gender', false],\n      ['voice', 'voice', false],\n      ['mood', 'mood', false],\n      ['pers', 'person', false],\n      ['comp', 'comparison', false]\n    ]\n    for (let feature of features) {\n      let localName = feature[0]\n      let featureType = feature[1]\n      let addToLemma = feature[2]\n      if (infl[localName]) {\n        let obj = model.typeFeature(Models.Feature.types[featureType]).createFeatures(infl[localName][0]._text, 1)\n        inflection.addFeature(obj)\n        // add this feature to this list of features for obligatory matching\n        inflection.constraints.obligatoryMatches.push(featureType)\n        if (addToLemma) {\n          lemma.addFeature(obj)\n        }\n      }\n    }\n    lexmodel.inflections = [ inflection ]\n    return new Models.Homonym([Models.ResourceProvider.getProxy(provider, lexmodel)], targetWord)\n  }\n\n  async getHomonym (lang, word) {\n    let xmlString = await this.fetch(lang, word)\n    if (xmlString) {\n      let jsonObj = xmlToJSON.parseString(xmlString)\n      jsonObj.words[0].word[0].entry[0].dict[0].hdwd[0]._attr = { lang: { _value: lang } }\n      let homonym = this.transform(jsonObj, jsonObj.words[0].word[0].form[0]._text)\n      return homonym\n    } else {\n      // No data found for this word\n      return undefined\n    }\n  }\n}\n\nexport default AlpheiosTreebankAdapter\n","import * as Models from 'alpheios-data-models'\n\n/**\n * Base Adapter Class for a Morphology Service Client\n */\nclass BaseAdapter {\n  /**\n   * Method which is used to prepare a lookup request according\n   * to the adapter specific logic\n   * @param {string} lang - the language code\n   * @param {string} word - the word to lookup\n   * @returns {string} the url for the request\n   */\n  prepareRequestUrl (lang, word) {\n    /** must be overridden in the adapter implementation class **/\n    return null\n  }\n\n  /**\n   * Lookup the supplied word using the preconfigured engines and\n   * and return a Homonym\n   * @param {symbol} languageID - A language ID as defined in Constants.LANG_XXX in data models\n   * @param {string} word - the word to lookup\n   * @return {Homonym} homonym object\n   */\n  async getHomonym (languageID, word) {\n    // implement in the derived adapter class\n    return undefined\n  }\n\n  /**\n   * Fetch response from a remote URL\n   * @param {symbol} languageID - A language ID\n   * @param {string} word - the word to lookup\n   * @returns {Promise} a promse which if successful resolves to json response object\n   *                    with the results of the analysis\n   */\n  fetch (languageID, word) {\n    const langCode = Models.LanguageModelFactory.getLanguageCodeFromId(languageID)\n    let url = this.prepareRequestUrl(langCode, word)\n    return new Promise((resolve, reject) => {\n      if (url) {\n        window.fetch(url).then(\n          function (response) {\n            try {\n              if (response.ok) {\n                let json = response.json()\n                resolve(json)\n              } else {\n                reject(response.statusText)\n              }\n            } catch (error) {\n              reject(error)\n            }\n          }\n        ).catch((error) => {\n          reject(error)\n        }\n        )\n      } else {\n        reject(new Error(`Unable to prepare parser request url for ${languageID.toString()}`))\n      }\n    })\n  }\n\n  /**\n   * Fetch test data to test the adapter\n   * @param {string} lang - the language code\n   * @param {string} word - the word to lookup\n   * @returns {Promise} a promse which if successful resolves to json response object\n   *                    with the test data\n   */\n  fetchTestData (lang, word) {\n    return new Promise((resolve, reject) => {\n      try {\n        let data = {}\n        resolve(data)\n      } catch (error) {\n        reject(error)\n      }\n    })\n  }\n\n  /**\n   * A function that maps a morphological service's specific data types and values into an inflection library standard.\n   * @param {object} jsonObj - A JSON data from the fetch request\n   * @param {object} targetWord - the original target word of the analysis\n   * @returns {Homonym} A library standard Homonym object.\n   */\n  transform (jsonObj, targetWord) {\n    return {}\n  }\n}\n\nexport default BaseAdapter\n","import AlpheiosTuftsAdapter from './tufts/adapter'\nimport BaseAdapter from './base_adapter'\nimport AlpheiosTreebankAdapter from './alpheiostb/adapter'\nexport { BaseAdapter, AlpheiosTuftsAdapter, AlpheiosTreebankAdapter }\n","import BaseAdapter from '../base_adapter'\nimport Whitakers from './engine/whitakers'\nimport Morpheusgrc from './engine/morpheusgrc'\nimport Aramorph from './engine/aramorph'\nimport Hazm from './engine/hazm'\nimport * as Models from 'alpheios-data-models'\nimport WordTestData from './engine/data/test-data'\nimport DefaultConfig from './config.json'\n\nclass AlpheiosTuftsAdapter extends BaseAdapter {\n  /**\n   * A Morph Client Adapter for the Tufts Morphology Service\n   * @constructor\n   * @param {object} config configuraiton object\n   */\n  constructor (config = {}) {\n    super()\n    try {\n      this.config = JSON.parse(DefaultConfig)\n    } catch (e) {\n      this.config = Object.assign({}, DefaultConfig)\n    }\n    Object.assign(this.config, config)\n    this.engineMap = new Map(([ Whitakers, Morpheusgrc, Aramorph, Hazm ]).map((e) => { return [ e.engine, e ] }))\n  }\n\n  getEngineLanguageMap (lang) {\n    if (this.config.engine[lang]) {\n      return this.engineMap.get(this.config.engine[lang][0])\n    } else {\n      return null\n    }\n  }\n\n  prepareRequestUrl (lang, word) {\n    let engine = this.getEngineLanguageMap(lang)\n    if (engine) {\n      let code = engine.engine\n      return this.config.url.replace('r_WORD', word).replace('r_ENGINE', code).replace('r_LANG', lang)\n    } else {\n      return null\n    }\n  }\n\n  fetchTestData (lang, word) {\n    return new Promise((resolve, reject) => {\n      try {\n        let wordData = new WordTestData().get(word)\n        let json = JSON.parse(wordData)\n        resolve(json)\n      } catch (error) {\n        // Word is not found in test data\n        reject(error)\n      }\n    })\n  }\n\n  /**\n   * A function that maps a morphological service's specific data types and values into an inflection library standard.\n   * @param {object} jsonObj - A JSON data from a Morphological Analyzer.\n   * @param {object} targetWord - the target of the analysis\n   * @returns {Models.Homonym} A library standard Homonym object.\n   */\n  transform (jsonObj, targetWord) {\n    'use strict'\n    let lexemes = []\n    let annotationBody = jsonObj.RDF.Annotation.Body\n    if (!Array.isArray(annotationBody)) {\n      /*\n      If only one lexeme is returned, Annotation Body will not be an array but rather a single object.\n      Let's convert it to an array so we can work with it in the same way no matter what format it is.\n      */\n      if (annotationBody) {\n        annotationBody = [annotationBody]\n      } else {\n        annotationBody = []\n      }\n    }\n    let providerUri = jsonObj.RDF.Annotation.creator.Agent.about\n    let providerRights = ''\n    if (jsonObj.RDF.Annotation.rights) {\n      providerRights = jsonObj.RDF.Annotation.rights.$\n    }\n    let provider = new Models.ResourceProvider(providerUri, providerRights)\n    for (let lexeme of annotationBody) {\n      let inflectionsJSON = lexeme.rest.entry.infl\n      if (!inflectionsJSON) {\n        inflectionsJSON = []\n      } else if (!Array.isArray(inflectionsJSON)) {\n        // If only one inflection returned, it is a single object, not an array of objects.\n        // Convert it to an array for uniformity.\n        inflectionsJSON = [inflectionsJSON]\n      }\n      let lemmaElements\n      let features = [\n        ['pofs', 'part'],\n        ['case', 'grmCase'],\n        ['gend', 'gender'],\n        ['decl', 'declension'],\n        ['conj', 'conjugation'],\n        ['area', 'area'],\n        ['age', 'age'],\n        ['geo', 'geo'],\n        ['freq', 'frequency'],\n        ['note', 'note'],\n        ['pron', 'pronunciation'],\n        ['kind', 'kind']\n      ]\n      if (lexeme.rest.entry.dict) {\n        if (Array.isArray(lexeme.rest.entry.dict)) {\n          lemmaElements = lexeme.rest.entry.dict\n        } else {\n          if (!lexeme.rest.entry.dict.hdwd && inflectionsJSON[0].term) {\n            lexeme.rest.entry.dict.hdwd = {}\n            lexeme.rest.entry.dict.hdwd.lang = inflectionsJSON[0].term.lang\n            lexeme.rest.entry.dict.hdwd.$ = inflectionsJSON[0].term.stem.$ + inflectionsJSON[0].term.suff.$\n          }\n          lemmaElements = [lexeme.rest.entry.dict]\n        }\n      } else if (inflectionsJSON.length > 0 && inflectionsJSON[0].term) {\n        lemmaElements = [ inflectionsJSON[0].term ]\n      }\n      // in rare cases (e.g. conditum in Whitakers) multiple dict entries\n      // exist - always use the lemma and language from the first\n      let language = lemmaElements[0].hdwd ? lemmaElements[0].hdwd.lang : lemmaElements[0].lang\n      // Get importer based on the language\n      let mappingData = this.getEngineLanguageMap(language)\n      let lemmas = []\n      let lexemeSet = []\n      for (let entry of lemmaElements.entries()) {\n        let shortdefs = []\n        let index = entry[0]\n        let elem = entry[1]\n        let lemmaText\n        if (elem.hdwd) {\n          lemmaText = elem.hdwd.$\n        }\n        if (!lemmaText || !language) {\n          continue\n        }\n        let lemma = mappingData.parseLemma(lemmaText, language)\n        lemmas.push(lemma)\n        for (let feature of features) {\n          mappingData.mapFeature(lemma, elem, ...feature, this.config.allowUnknownValues)\n        }\n        let meanings = lexeme.rest.entry.mean\n        if (!Array.isArray(meanings)) {\n          meanings = [meanings]\n        }\n        meanings = meanings.filter((m) => m)\n        // if we have multiple dictionary elements, take the meaning with the matching index\n        if (lemmaElements.length > 1) {\n          if (meanings && meanings[index]) {\n            let meaning = meanings[index]\n            // TODO: convert a source-specific language code to ISO 639-3 if don't match\n            let lang = meaning.lang ? meaning.lang : 'eng'\n            shortdefs.push(Models.ResourceProvider.getProxy(provider,\n              new Models.Definition(meaning.$, lang, 'text/plain', lemmas[index].word)))\n          }\n        } else {\n          // Changed to prevent some weird \"Array Iterator.prototype.next called on incompatible receiver [object Unknown]\" error\n          let sDefs = meanings.map(meaning => {\n            let lang = meaning.lang ? meaning.lang : 'eng'\n            return Models.ResourceProvider.getProxy(provider,\n              new Models.Definition(meaning.$, lang, 'text/plain', lemma.word))\n          })\n          shortdefs.push(...sDefs)\n        }\n        let lexmodel = new Models.Lexeme(lemma, [])\n\n        lexmodel.meaning.appendShortDefs(shortdefs)\n        lexemeSet.push(Models.ResourceProvider.getProxy(provider, lexmodel))\n      }\n      if (lemmas.length === 0) {\n        continue\n      }\n      let inflections = []\n      for (let inflectionJSON of inflectionsJSON) {\n        let stem = inflectionJSON.term.stem ? inflectionJSON.term.stem.$ : null\n        let suffix = inflectionJSON.term.suff ? inflectionJSON.term.suff.$ : null\n        let prefix = inflectionJSON.term.pref ? inflectionJSON.term.pref.$ : null\n        let xmpl = inflectionJSON.xmple ? inflectionJSON.xmpl.$ : null\n        let inflection = new Models.Inflection(stem, mappingData.model.languageID, suffix, prefix, xmpl)\n        if (targetWord) {\n          inflection.addFeature(new Models.Feature(Models.Feature.types.fullForm, targetWord, mappingData.model.languageID))\n        }\n        // Parse whatever grammatical features we're interested in\n        mappingData.mapFeature(inflection, inflectionJSON, 'pofs', 'part', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'case', 'grmCase', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'decl', 'declension', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'num', 'number', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'gend', 'gender', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'conj', 'conjugation', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'tense', 'tense', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'voice', 'voice', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'mood', 'mood', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'pers', 'person', this.config.allowUnknownValues)\n        mappingData.mapFeature(inflection, inflectionJSON, 'comp', 'comparison', this.config.allowUnknownValues)\n        if (inflectionJSON.stemtype) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'stemtype', 'stemtype', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.derivtype) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'derivtype', 'derivtype', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.dial) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'dial', 'dialect', this.config.allowUnknownValues)\n        }\n        if (inflectionJSON.morph) {\n          mappingData.mapFeature(inflection, inflectionJSON, 'morph', 'morph', this.config.allowUnknownValues)\n        }\n        // we only use the inflection if it tells us something the dictionary details do not\n        if (inflection[Models.Feature.types.grmCase] ||\n          inflection[Models.Feature.types.tense] ||\n          inflection[Models.Feature.types.mood] ||\n          inflection[Models.Feature.types.voice] ||\n          inflection[Models.Feature.types.person] ||\n          inflection[Models.Feature.types.comparison] ||\n          inflection[Models.Feature.types.stemtype] ||\n          inflection[Models.Feature.types.derivtype] ||\n          inflection[Models.Feature.types.dialect] ||\n          inflection[Models.Feature.types.morph] ||\n          inflection[Models.Feature.types.example]) {\n          inflections.push(inflection)\n        }\n        // inflection can provide lemma decl, pofs, conj\n        for (let lemma of lemmas) {\n          if (!lemma.features[Models.Feature.types.part]) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'pofs', 'part', this.config.allowUnknownValues)\n          }\n          // only take declension from inflection if lemma has no part of speech or its the same as the inflection\n          if (!lemma.features[Models.Feature.types.declension] &&\n            (!lemma.features[Models.Feature.types.part] || lemma.features[Models.Feature.types.part].isEqual(inflection[Models.Feature.types.part]))) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'decl', 'declension', this.config.allowUnknownValues)\n          }\n          // only take conjugation from inflection if lemma has a part of speech and its the same as the inflection\n          if (!lemma.features[Models.Feature.types.conjugation] &&\n            (!lemma.features[Models.Feature.types.part] || lemma.features[Models.Feature.types.part].isEqual(inflection[Models.Feature.types.part]))) {\n            mappingData.mapFeature(lemma, inflectionJSON, 'conj', 'conjugation', this.config.allowUnknownValues)\n          }\n        }\n      }\n      for (let lex of lexemeSet) {\n        // only process if we have a lemma that differs from the target\n        // word or if we have at least a part of speech\n        if (mappingData.reportLexeme(lex)) {\n          lex.inflections = inflections\n          lexemes.push(lex)\n        }\n      }\n    }\n    if (lexemes.length > 0) {\n      return new Models.Homonym(lexemes, targetWord)\n    } else {\n      return undefined\n    }\n  }\n\n  async getHomonym (languageID, word) {\n    let jsonObj = await this.fetch(languageID, word)\n    if (jsonObj) {\n      let homonym = this.transform(jsonObj, word)\n      homonym.lexemes.sort(Models.Lexeme.getSortByTwoLemmaFeatures(Models.Feature.types.frequency, Models.Feature.types.part))\n      return homonym\n    } else {\n      // No data found for this word\n      return undefined\n    }\n  }\n}\n\nexport default AlpheiosTuftsAdapter\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.ArabicLanguageModel, 'aramorph')\n\nexport default data\n","import Cupidinibus from './latin_noun_cupidinibus.json'\nimport Mare from './latin_noun_adj_mare.json'\nimport Cepit from './latin_verb_cepit.json'\nimport Pilsopo from './greek_noun_pilsopo.json'\n\nclass WordTestData {\n  constructor () {\n    this._words = {\n      'cupidinibus': Cupidinibus,\n      'mare': Mare,\n      'cepit': Cepit,\n      'φιλόσοφος': Pilsopo\n    }\n  }\n\n  get (word) {\n    if (this._words.hasOwnProperty(word)) {\n      return this._words[word]\n    }\n    throw new Error(`Word \"${word}\" does not exist in test data`)\n  }\n}\nexport default WordTestData\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.PersianLanguageModel, 'hazm')\n\n// hazm allow all lemmas in without respect features as all we use it for is lemmatizing\ndata.setLexemeFilter(function (lexeme) { return Boolean(lexeme.lemma.word) })\n\nexport default data\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.GreekLanguageModel, 'morpheusgrc')\n\n/*\nBelow are value conversion maps for each grammatical feature to be parsed.\nFormat:\ndata.addFeature(typeName).add(providerValueName, LibValueName);\n(functions are chainable)\nTypes and values that are unknown (undefined) will be skipped during parsing.\n */\n\ndata.addFeature(Models.Feature.types.gender).importer\n  .map('masculine feminine', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2]])\n\ndata.addFeature(Models.Feature.types.declension).importer\n  .map('1st & 2nd', [[Models.Constants.ORD_1ST, 1], [Models.Constants.ORD_2ND, 2]])\n\nexport default data\n","import ImportData from '../lib'\nimport * as Models from 'alpheios-data-models'\n\nlet data = new ImportData(Models.LatinLanguageModel, 'whitakerLat')\n\n/*\nBelow are value conversion maps for each grammatical feature to be parsed.\nFormat:\ndata.addFeature(typeName).add(providerValueName, LibValueName);\n(functions are chainable)\nTypes and values that are unknown (undefined) will be skipped during parsing.\n */\n\n// TODO  - per inflections.xsd\n// Whitakers Words uses packon and tackon in POFS, not sure how\n\ndata.addFeature(Models.Feature.types.gender).importer\n  .map('common', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2]])\n  .map('all', [[Models.Constants.GEND_MASCULINE, 1], [Models.Constants.GEND_FEMININE, 2], [Models.Constants.GEND_NEUTER, 3]])\n\ndata.addFeature(Models.Feature.types.tense).importer\n  .map('future_perfect', Models.Constants.TENSE_FUTURE_PERFECT)\n\ndata.setLemmaParser(function (lemma) {\n  // Whitaker's Words returns principal parts for some words\n  // and sometimes has a space separted stem and suffix\n  let parsed, primary\n  let parts = []\n  let lemmas = lemma.split(', ')\n  for (let [index, l] of lemmas.entries()) {\n    let normalized = l.split(' ')[0]\n    if (index === 0) {\n      primary = normalized\n    }\n    parts.push(normalized)\n  }\n  if (primary) {\n    parsed = new Models.Lemma(primary, this.model.languageCode, parts)\n  }\n\n  return parsed\n})\n\nexport default data\n","/*\nObjects of a morphology analyzer's library\n */\nimport { Feature, Lemma, FeatureImporter } from 'alpheios-data-models'\n\n/**\n * Holds all information required to transform from morphological analyzer's grammatical feature values to the\n * library standards. There is one ImportData object per language.\n */\nclass ImportData {\n  /**\n     * Creates an ImportData object for the language provided.\n     * @param {Function<LanguageModel>} model - A language model of the import data.\n     * @param {string} engine - engine code\n     */\n  constructor (model, engine) {\n    'use strict'\n    this.model = model\n    this.engine = engine\n    // add all the features that the language supports so that we\n    // can return the default values if we don't need to import a mapping\n    for (let featureName of Object.keys(this.model.features)) {\n      this.addFeature(featureName)\n    }\n    // may be overridden by specific engine use via setLemmaParser\n    this.parseLemma = function (lemma) { return new Lemma(lemma, this.model.languageID) }\n    // may be overridden by specific engine use via setPropertyParser - default just returns the property value\n    // as a list\n    this.parseProperty = function (propertyName, propertyValue) {\n      let propertyValues = []\n      if (propertyName === 'decl') {\n        propertyValues = propertyValue.split('&').map((p) => p.trim())\n      } else if (propertyName === 'comp' && propertyValue === 'positive') {\n        propertyValues = []\n      } else {\n        propertyValues = [propertyValue]\n      }\n      return propertyValues\n    }\n    // may be overridden by specifc engine use via setLexemeFilter - default assumes we will have a part of speech\n    this.reportLexeme = function (lexeme) {\n      return lexeme.lemma.features[Feature.types.part]\n    }\n  }\n\n  /**\n     * Adds a grammatical feature whose values to be mapped.\n     * @param {string} featureName - A name of a grammatical feature (i.e. declension, number, etc.)\n     * @return {Object} An object that represent a newly created grammatical feature.\n     */\n  addFeature (featureName) {\n    this[featureName] = {}\n    let model = this.model\n\n    this[featureName].add = function add (providerValue, alpheiosValue) {\n      this[providerValue] = alpheiosValue\n      return this\n    }\n\n    this[featureName].get = function get (providerValue, sortOrder = 1, allowUnknownValues = false) {\n      let mappedValue = []\n      if (!this.importer.has(providerValue)) {\n        // if the providerValue matches the model value or the model value\n        // is unrestricted, return a feature with the providerValue and order\n        if (model.typeFeature(featureName).hasValue(providerValue) ||\n            model.typeFeature(featureName).valuesUnrestricted) {\n          mappedValue = model.typeFeature(featureName).createFeature(providerValue, sortOrder)\n        } else {\n          let message = `Unknown value \"${providerValue}\" of feature \"${featureName}\" for ${model.languageCode} (allowed = ${allowUnknownValues})`\n          if (allowUnknownValues) {\n            console.log(message)\n            mappedValue = model.typeFeature(featureName).createFeature(providerValue, sortOrder)\n          } else {\n            throw new Error(message)\n          }\n        }\n      } else {\n        let tempValue = this.importer.get(providerValue)\n        if (Array.isArray(tempValue)) {\n          mappedValue = model.typeFeature(featureName).createFeatures(tempValue, sortOrder)\n        } else {\n          mappedValue = model.typeFeature(featureName).createFeature(tempValue, sortOrder)\n        }\n      }\n      return mappedValue\n    }\n\n    /**\n     * @param {Object[]} data - An array of objects with `providerData` (an item value) and `sortOrder` fields\n     * @param allowUnknownValues\n     * @return {Feature}\n     */\n    this[featureName].getMultiple = function get (data, allowUnknownValues = false) {\n      let values = [] // Converts values from `data` into `values` array\n      for (const item of data) {\n        if (this.importer.has(item.providerValue)) {\n          let value = this.importer.get(item.providerValue)\n          if (Array.isArray(value)) {\n            // if the import returns an array, it should already have the sortOrder\n            values = value\n          } else {\n            values = [[value, item.sortOrder]]\n          }\n        } else if (model.typeFeature(featureName).hasValue(item.providerValue) ||\n          model.typeFeature(featureName).valuesUnrestricted) {\n          values.push([item.providerValue, item.sortOrder])\n        } else {\n          let message = `Unknown value \"${item.providerValue}\" of feature \"${featureName}\" for ${model.languageCode} (allowed = ${allowUnknownValues})`\n          if (allowUnknownValues) {\n            console.log(message)\n            values.push([item.providerValue, item.sortOrder])\n          } else {\n            throw new Error(message)\n          }\n        }\n      }\n      return model.typeFeature(featureName).createFeatures(values)\n    }\n\n    this[featureName].importer = new FeatureImporter()\n\n    return this[featureName]\n  }\n\n  /**\n   * Add an engine-specific lemma parser\n   */\n  setLemmaParser (callback) {\n    this.parseLemma = callback\n  }\n\n  /**\n   * Add an engine-specific property parser\n   */\n  setPropertyParser (callback) {\n    this.parseProperty = callback\n  }\n\n  /**\n   * Add an engine-specific lexeme filter\n   */\n  setLexemeFilter (callback) {\n    this.reportLexeme = callback\n  }\n\n  /**\n   * Maps property of a single feature type to a single Feature object with one or more values\n   * (if this feature has multiple values). Feature is stored as a property of the supplied model object.\n   * @param {object} model the model object to which the feature will be added\n   * @param {object} inputElem the input data element\n   * @param {object} inputName the  property name in the input data\n   * @param {string} featureName the name of the feature it will be mapped to\n   * @param {boolean} allowUnknownValues flag to indicate if unknown values are allowed\n   */\n  mapFeature (model, inputElem, inputName, featureName, allowUnknownValues) {\n    let values = []\n    let inputItem = inputElem[inputName]\n    if (inputItem) {\n      if (Array.isArray(inputItem)) {\n        // There are multiple values of this feature\n        for (let e of inputItem) {\n          values.push(...this.parseProperty(inputName, e.$))\n        }\n      } else {\n        values = this.parseProperty(inputName, inputItem.$)\n      }\n      // `values` is always an array as an array is a return value of `parseProperty`\n    }\n    if (values.length > 0) {\n      // There are some values found\n      values = values.map(v => { return { providerValue: v, sortOrder: inputItem.order ? inputItem.order : 1 } })\n      let feature = this[Feature.types[featureName]].getMultiple(values, allowUnknownValues)\n      model.addFeature(feature)\n    }\n  }\n}\nexport default ImportData\n","module.exports = __WEBPACK_EXTERNAL_MODULE_alpheios_data_models__;"],"sourceRoot":""}